# Comparing `tmp/DDesignerAPI-0.0.2.4-py3-none-any.whl.zip` & `tmp/DDesignerAPI-0.0.2.6-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,31 +1,31 @@
-Zip file size: 48291 bytes, number of entries: 29
--rw-rw-r--  2.0 unx      962 b- defN 23-May-12 07:44 ddesigner_api/__init__.py
--rw-rw-r--  2.0 unx      725 b- defN 23-May-12 07:44 ddesigner_api/numpy/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 23-May-12 07:44 ddesigner_api/numpy/examples/__init__.py
--rw-rw-r--  2.0 unx     2583 b- defN 23-May-12 07:44 ddesigner_api/numpy/examples/examples_numpy.py
--rw-rw-r--  2.0 unx      738 b- defN 23-May-12 07:44 ddesigner_api/numpy/xwn/__init__.py
--rw-rw-r--  2.0 unx     4852 b- defN 23-May-12 07:44 ddesigner_api/numpy/xwn/optimization.py
--rw-rw-r--  2.0 unx      770 b- defN 23-May-12 07:44 ddesigner_api/pytorch/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 23-May-12 07:44 ddesigner_api/pytorch/examples/__init__.py
--rw-rw-r--  2.0 unx     5016 b- defN 23-May-12 07:44 ddesigner_api/pytorch/examples/examples_pytorch.py
--rw-rw-r--  2.0 unx      736 b- defN 23-May-12 07:44 ddesigner_api/pytorch/xwn/__init__.py
--rw-rw-r--  2.0 unx    63140 b- defN 23-May-12 07:44 ddesigner_api/pytorch/xwn/torch_nn.py
--rw-rw-r--  2.0 unx     5030 b- defN 23-May-12 07:44 ddesigner_api/pytorch/xwn/torch_opt.py
--rw-rw-r--  2.0 unx      873 b- defN 23-May-12 07:44 ddesigner_api/tensorflow/__init__.py
--rw-rw-r--  2.0 unx    11329 b- defN 23-May-12 07:44 ddesigner_api/tensorflow/dpi_blocks.py
--rw-rw-r--  2.0 unx     6208 b- defN 23-May-12 07:44 ddesigner_api/tensorflow/dpi_layers.py
--rw-rw-r--  2.0 unx        0 b- defN 23-May-12 07:44 ddesigner_api/tensorflow/examples/__init__.py
--rw-rw-r--  2.0 unx     7883 b- defN 23-May-12 07:44 ddesigner_api/tensorflow/examples/examples_keras.py
--rw-rw-r--  2.0 unx     3021 b- defN 23-May-12 07:44 ddesigner_api/tensorflow/examples/examples_tensorflow.py
--rw-rw-r--  2.0 unx      790 b- defN 23-May-12 07:44 ddesigner_api/tensorflow/xwn/__init__.py
--rw-rw-r--  2.0 unx    16322 b- defN 23-May-12 07:44 ddesigner_api/tensorflow/xwn/base_conv.py
--rw-rw-r--  2.0 unx    29451 b- defN 23-May-12 07:44 ddesigner_api/tensorflow/xwn/keras_layers.py
--rw-rw-r--  2.0 unx     5013 b- defN 23-May-12 07:44 ddesigner_api/tensorflow/xwn/keras_opt.py
--rw-rw-r--  2.0 unx     9240 b- defN 23-May-12 07:44 ddesigner_api/tensorflow/xwn/tf_nn.py
--rw-rw-r--  2.0 unx     4046 b- defN 23-May-12 07:44 ddesigner_api/tensorflow/xwn/tf_opt.py
--rwxrwxr-x  2.0 unx     9136 b- defN 23-May-12 07:54 DDesignerAPI-0.0.2.4.dist-info/LICENSE
--rw-rw-r--  2.0 unx     6269 b- defN 23-May-12 07:54 DDesignerAPI-0.0.2.4.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 23-May-12 07:54 DDesignerAPI-0.0.2.4.dist-info/WHEEL
--rw-rw-r--  2.0 unx       14 b- defN 23-May-12 07:54 DDesignerAPI-0.0.2.4.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     2735 b- defN 23-May-12 07:54 DDesignerAPI-0.0.2.4.dist-info/RECORD
-29 files, 196974 bytes uncompressed, 43761 bytes compressed:  77.8%
+Zip file size: 48614 bytes, number of entries: 29
+-rw-rw-r--  2.0 unx      962 b- defN 23-May-18 11:32 ddesigner_api/__init__.py
+-rw-rw-r--  2.0 unx      725 b- defN 23-May-18 11:32 ddesigner_api/numpy/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-May-18 11:32 ddesigner_api/numpy/examples/__init__.py
+-rw-rw-r--  2.0 unx     2583 b- defN 23-May-18 11:32 ddesigner_api/numpy/examples/examples_numpy.py
+-rw-rw-r--  2.0 unx      738 b- defN 23-May-18 11:32 ddesigner_api/numpy/xwn/__init__.py
+-rw-rw-r--  2.0 unx     4852 b- defN 23-May-18 11:32 ddesigner_api/numpy/xwn/optimization.py
+-rw-rw-r--  2.0 unx      770 b- defN 23-May-18 11:32 ddesigner_api/pytorch/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-May-18 11:32 ddesigner_api/pytorch/examples/__init__.py
+-rw-rw-r--  2.0 unx     7416 b- defN 23-May-18 11:32 ddesigner_api/pytorch/examples/examples_pytorch.py
+-rw-rw-r--  2.0 unx      736 b- defN 23-May-18 11:32 ddesigner_api/pytorch/xwn/__init__.py
+-rw-rw-r--  2.0 unx    65337 b- defN 23-May-18 11:32 ddesigner_api/pytorch/xwn/torch_nn.py
+-rw-rw-r--  2.0 unx     5223 b- defN 23-May-18 11:32 ddesigner_api/pytorch/xwn/torch_opt.py
+-rw-rw-r--  2.0 unx      873 b- defN 23-May-18 11:32 ddesigner_api/tensorflow/__init__.py
+-rw-rw-r--  2.0 unx    11329 b- defN 23-May-18 11:32 ddesigner_api/tensorflow/dpi_blocks.py
+-rw-rw-r--  2.0 unx     6208 b- defN 23-May-18 11:32 ddesigner_api/tensorflow/dpi_layers.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-May-18 11:32 ddesigner_api/tensorflow/examples/__init__.py
+-rw-rw-r--  2.0 unx     7883 b- defN 23-May-18 11:32 ddesigner_api/tensorflow/examples/examples_keras.py
+-rw-rw-r--  2.0 unx     3021 b- defN 23-May-18 11:32 ddesigner_api/tensorflow/examples/examples_tensorflow.py
+-rw-rw-r--  2.0 unx      790 b- defN 23-May-18 11:32 ddesigner_api/tensorflow/xwn/__init__.py
+-rw-rw-r--  2.0 unx    16322 b- defN 23-May-18 11:32 ddesigner_api/tensorflow/xwn/base_conv.py
+-rw-rw-r--  2.0 unx    29451 b- defN 23-May-18 11:32 ddesigner_api/tensorflow/xwn/keras_layers.py
+-rw-rw-r--  2.0 unx     5013 b- defN 23-May-18 11:32 ddesigner_api/tensorflow/xwn/keras_opt.py
+-rw-rw-r--  2.0 unx     9240 b- defN 23-May-18 11:32 ddesigner_api/tensorflow/xwn/tf_nn.py
+-rw-rw-r--  2.0 unx     4046 b- defN 23-May-18 11:32 ddesigner_api/tensorflow/xwn/tf_opt.py
+-rwxrwxr-x  2.0 unx     9136 b- defN 23-May-18 11:44 DDesignerAPI-0.0.2.6.dist-info/LICENSE
+-rw-rw-r--  2.0 unx     6559 b- defN 23-May-18 11:44 DDesignerAPI-0.0.2.6.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 23-May-18 11:44 DDesignerAPI-0.0.2.6.dist-info/WHEEL
+-rw-rw-r--  2.0 unx       14 b- defN 23-May-18 11:44 DDesignerAPI-0.0.2.6.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     2735 b- defN 23-May-18 11:44 DDesignerAPI-0.0.2.6.dist-info/RECORD
+29 files, 202054 bytes uncompressed, 44084 bytes compressed:  78.2%
```

## zipnote {}

```diff
@@ -66,23 +66,23 @@
 
 Filename: ddesigner_api/tensorflow/xwn/tf_nn.py
 Comment: 
 
 Filename: ddesigner_api/tensorflow/xwn/tf_opt.py
 Comment: 
 
-Filename: DDesignerAPI-0.0.2.4.dist-info/LICENSE
+Filename: DDesignerAPI-0.0.2.6.dist-info/LICENSE
 Comment: 
 
-Filename: DDesignerAPI-0.0.2.4.dist-info/METADATA
+Filename: DDesignerAPI-0.0.2.6.dist-info/METADATA
 Comment: 
 
-Filename: DDesignerAPI-0.0.2.4.dist-info/WHEEL
+Filename: DDesignerAPI-0.0.2.6.dist-info/WHEEL
 Comment: 
 
-Filename: DDesignerAPI-0.0.2.4.dist-info/top_level.txt
+Filename: DDesignerAPI-0.0.2.6.dist-info/top_level.txt
 Comment: 
 
-Filename: DDesignerAPI-0.0.2.4.dist-info/RECORD
+Filename: DDesignerAPI-0.0.2.6.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## ddesigner_api/pytorch/examples/examples_pytorch.py

```diff
@@ -130,28 +130,95 @@
             bit=4,
             max_scale=4.0,
         )
         m.weight.copy_(kernel)
         print(m(x))
     print('==========================')
 
+def fixed_input_conv1d():
+    x_in = np.array([                                                                            
+        2, 1, 2, 0, 1,                                                                  
+        1, 3, 2, 2, 3,                                                                  
+        1, 1, 3, 3, 0,                                                                  
+        2, 2, 0, 1, 1,
+        3, 1, 0, 3, 1,
+        0, 0, 3, 1, 2, ])                                                              
+    kernel_in = np.array([                                                                        
+        2, 0.1, 3,                                                                   
+        0, 0.3, 1,  ])                                                               
+    x = torch.from_numpy(np.reshape(x_in, (2,3,5)).astype('float32'))
+    kernel = torch.from_numpy(np.reshape(kernel_in, (1,3,2)).astype('float32'))
+    print('Input Shape = {}, Kernel Shape = {}'.format(x.shape, kernel.shape))
+    
+    print('====== torch.nn.Conv1d ======')
+    with torch.no_grad():
+        m = torch.nn.Conv1d(
+            in_channels=3, 
+            out_channels=1, 
+            kernel_size=2, 
+            stride=1, 
+            padding='valid', 
+            bias=False
+        )
+        m.weight.copy_(kernel)
+        # o = torch.permute(m(x), (0,2,3,1))
+        o = m(x)
+        print(o)
+    print('==========================')
+    
+    print('====== dpi_nn.Conv1d (without opt) =====')
+    with torch.no_grad():
+        m = nn.Conv1d(
+            in_channels=3, 
+            out_channels=1, 
+            kernel_size=2, 
+            stride=1, 
+            padding='valid', 
+            bias=False
+        )
+        m.weight.copy_(kernel)
+        o = m(x)
+        print(o)
+    print('==========================')
+    
+    print('====== dpi_nn.Conv1d (with opt) =====')
+    with torch.no_grad():
+        m = nn.Conv1d(
+            in_channels=3, 
+            out_channels=1, 
+            kernel_size=2, 
+            stride=1, 
+            padding='valid', 
+            bias=False,
+            use_transform=True,
+            bit=4,
+            max_scale=4.0,
+        )
+        m.weight.copy_(kernel)
+        o = m(x)
+        print(o)
+    print('==========================')
+
 
 def main():
     print('====== PYTORCH Examples======')
 
     while True:
         print('1: Fixed  Float32 Input Conv2D')
         print('2: Random Float32 Input Conv2D')
+        print('3: Fixed  Float32 Input Conv1D')
         print('q: Quit')
         print('>>> Select Case:')
         cmd = input()
         if cmd == '1':
             fixed_input()
         elif cmd == '2':
             random_input()
+        elif cmd == '3':
+            fixed_input_conv1d()
         elif cmd == 'q': 
             break
         
     return True
```

## ddesigner_api/pytorch/xwn/torch_nn.py

```diff
@@ -1,23 +1,79 @@
 # -*- coding: utf-8 -*-
 import math
 import warnings
 
 import torch
 from torch import Tensor
 from torch.nn import functional as F
-from torch.nn.modules.utils import _pair
-from torch.nn.common_types import _size_2_t
+from torch.nn.modules.utils import _pair, _single
+from torch.nn.common_types import _size_2_t, _size_1_t
 from torch.nn.modules.conv import _ConvNd
 from typing import Optional, List, Tuple, Union
 
 from .torch_opt import Optimization
 
 
 
+class Conv1d(_ConvNd):
+    def __init__(
+        self,
+        in_channels: int,
+        out_channels: int,
+        kernel_size: _size_1_t,
+        stride: _size_1_t = 1,
+        padding: Union[str, _size_1_t] = 0,
+        dilation: _size_1_t = 1,
+        groups: int = 1,
+        bias: bool = True,
+        padding_mode: str = 'zeros',  # TODO: refine this type
+        device=None,
+        dtype=None,
+        use_transform=False, 
+        use_pruning=False, 
+        bit=4, 
+        max_scale=4.0,
+        prun_weight=0.5,
+    ) -> None:
+        factory_kwargs = {'device': device, 'dtype': dtype}
+        # we create new variables below to make mypy happy since kernel_size has
+        # type Union[int, Tuple[int]] and kernel_size_ has type Tuple[int]
+        kernel_size_ = _single(kernel_size)
+        stride_ = _single(stride)
+        padding_ = padding if isinstance(padding, str) else _single(padding)
+        dilation_ = _single(dilation)
+        super(Conv1d, self).__init__(
+            in_channels, out_channels, kernel_size_, stride_, padding_, dilation_,
+            False, _single(0), groups, bias, padding_mode, **factory_kwargs)
+
+        # Add optimization kernel
+        self.opt = Optimization(
+            use_transform=use_transform, 
+            bit=bit, 
+            max_scale=max_scale,
+            use_pruning=use_pruning, 
+            prun_weight=prun_weight,
+            transpose=False,
+        )
+        self.opt.set_shape(self.weight.shape)
+
+    def _conv_forward(self, input: Tensor, weight: Tensor, bias: Optional[Tensor]):
+        if self.padding_mode != 'zeros':
+            return F.conv1d(F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),
+                            weight, bias, self.stride,
+                            _single(0), self.dilation, self.groups)
+        return F.conv1d(input, weight, bias, self.stride,
+                        self.padding, self.dilation, self.groups)
+
+    def forward(self, input: Tensor) -> Tensor:
+        weight = self.opt.optimize(self.weight)
+        return self._conv_forward(input, weight, self.bias)
+        # return self._conv_forward(input, self.weight, self.bias)
+
+
 class Conv2d(_ConvNd):
     def __init__(
         self,
         in_channels: int,
         out_channels: int,
         kernel_size: _size_2_t,
         stride: _size_2_t = 1,
@@ -60,16 +116,16 @@
                             weight, bias, self.stride,
                             _pair(0), self.dilation, self.groups)
         return F.conv2d(input, weight, bias, self.stride,
                         self.padding, self.dilation, self.groups)
 
     def forward(self, input: Tensor) -> Tensor:
         weight = self.opt.optimize(self.weight)
-        # return self._conv_forward(input, self.weight, self.bias)
         return self._conv_forward(input, weight, self.bias)
+        # return self._conv_forward(input, self.weight, self.bias)
 
 
 
 # class Conv1d(_ConvNd):
 #     __doc__ = r"""Applies a 1D convolution over an input signal composed of several input
 #     planes.
 #
```

## ddesigner_api/pytorch/xwn/torch_opt.py

```diff
@@ -124,33 +124,38 @@
         mask = mask.type(xdtype)
         return mask
 
     def optimize(self, x):
         '''
         x is AutoCastDistribuedVariable
         '''
-        x = torch.permute(x, (2,3,1,0))
+        x = torch.permute(x, self.default_axis_0)
         _x = torch.permute(x, self.transpose_axis)
         x_tr = self._transform(_x)
         x_mask = self._pruning(_x)
         x_opt = x_tr * x_mask
         x = torch.permute(x_opt, self.transpose_axis)
-        x = torch.permute(x, (3,2,0,1))
+        x = torch.permute(x, self.default_axis_1)
         return x
 
     def set_shape(self, shape):
         self.shape = shape
         self.bypass_transform = (self.bit < 1) or not self.use_transform
         self.kernel_axis = list(range(len(shape) - 2))
 
         if len(self.shape) == 4:
             if self.transpose:
                 self.transpose_axis = (0,1,3,2)
             else:
                 self.transpose_axis = (0,1,2,3)
+            self.default_axis_0 = (2,3,1,0)
+            self.default_axis_1 = (3,2,0,1)
+
         elif len(self.shape) == 3:
             if self.transpose:
                 self.transpose_axis = (0,2,1)
             else:
                 self.transpose_axis = (0,1,2)
+            self.default_axis_0 = (2,1,0)
+            self.default_axis_1 = (2,1,0)
```

## Comparing `DDesignerAPI-0.0.2.4.dist-info/LICENSE` & `DDesignerAPI-0.0.2.6.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `DDesignerAPI-0.0.2.4.dist-info/METADATA` & `DDesignerAPI-0.0.2.6.dist-info/METADATA`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: DDesignerAPI
-Version: 0.0.2.4
+Version: 0.0.2.6
 Summary: Deep-learning Designer: Deep-Learning Training Optimization & Layers API(like Keras)
 Home-page: https://github.com/DPI/TrainingAPI
 Author: Deeper-I
 Author-email: dean@deeper-i.com
 License: Apache-2.0
 Keywords: deeper-i,xwn,tensorflow,keras
 Platform: UNKNOWN
@@ -35,43 +35,43 @@
 
 ## 2.2. Components of Network 
 ### 2.2.1. Layers
 #### 2.2.1.1. Summary
 |Platform|SqeezeAndExcitation1D|SqeezeAndExcitation2D|
 |:---:|:---:|:---:|
 |**TF-Keras**|O|O|
-#### 2.2.1.1. Detail
-* SqeezeAndExcitation1D
-* SqeezeAndExcitation2D
+#### 2.2.1.2. Detail
+* SqeezeAndExcitation1D(SE1D)
+* SqeezeAndExcitation2D(SE2D)
 <br/><br/>
 ### 2.2.2. Blocks
 #### 2.2.2.1. Summary
-|Platform|Conv1D|Conv2D|FullyConneted|Conv2DTranspose|
+|Platform|Conv1DBlock|Conv2DBlock|TConv2DBlock|FCBlock|
 |:---:|:---:|:---:|:---:|:---:|
 |**TF-Keras**|O|O|O|O|
-#### 2.2.2.1. Detail
-* Conv1DBlock
-* Conv2DBlock
-* FCBlock
-* TConv2DBlock
+#### 2.2.2.2. Detail
+* Conv1DBlock   : 1D-Convolution Block (CONV  + BN + ACT + DROPOUT + SE)
+* Conv2DBlock   : 2D-Convolution Block (CONV  + BN + ACT + DROPOUT + SE)
+* TConv2DBlock  : 2D-Convolution Block (TCONV + BN + ACT + DROPOUT + SE)
+* FCBlock       : FullyConnected Block (FC    + BN + ACT + DROPOUT)
 <br/><br/>
 ## 2.3. XWN (**Applies only to convolution operations**)
 ### 2.3.1. Transform Configuration (data type / default value / description) 
 * transform     : bool  / False / Choose whether to use
 * bit           : int   / 4     / Quantization range (bit-1 ** 2)
 * max_scale     : float / 4.0   / Max value
 ### 2.3.2. Pruning Configuration
 * pruning       : bool  / False / Choose whether to use
 * prun_weight   : float / 0.5   / Weights for puning edge generation
 ### 2.3.3. Summary
 |Platform|Conv1D|Conv2D|FullyConneted|Conv2DTranspose|
 |:---:|:---:|:---:|:---:|:---:|
 |**TF**|O|O|X|O|
 |**TF-Keras**|O|O|X|O|
-|**PyTorch**|X|O|X|X|
+|**PyTorch**|O|O|X|X|
 
 <br/><br/>
 
 # 3. Command Usage
 ## 3.1. Blocks  
 ### 3.1.1. Keras
 #### 3.1.1.1. Conv1DBlock
@@ -176,14 +176,15 @@
 
 ### 3.3.3. PyTorch
         >>> import ddesigner_api.pytorch.examples.examples_pytorch as ex
         >>> ex.main()
         >>> ====== PYTORCH Examples======
         >>> 1: Fixed  Float32 Input Conv2D
         >>> 2: Random Float32 Input Conv2D
+        >>> 3: Fixed  Float32 Input Conv1D
         >>> q: Quit
         >>> Select Case: ...
 
 ### 3.3.4. Numpy
         >>> import ddesigner_api.numpy.examples.examples_numpy as ex
         >>> ex.main()
         >>> ====== NUMPY Examples======
```

## Comparing `DDesignerAPI-0.0.2.4.dist-info/RECORD` & `DDesignerAPI-0.0.2.6.dist-info/RECORD`

 * *Files 20% similar despite different names*

```diff
@@ -2,28 +2,28 @@
 ddesigner_api/numpy/__init__.py,sha256=JRro7LhcyUvKHQH9_trioRisLxy-IMnTfJJVhkW0L9w,725
 ddesigner_api/numpy/examples/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 ddesigner_api/numpy/examples/examples_numpy.py,sha256=wjHtTJVuRkWTckFtG7hLGpW3coOgctTYpGwBg_uhahk,2583
 ddesigner_api/numpy/xwn/__init__.py,sha256=FtLZM4Yg3OqOlt2fxtmbDGLwsBMLmXMoRyGp3PUERvY,738
 ddesigner_api/numpy/xwn/optimization.py,sha256=nw9ti-9ZTD8uptZoKNMm2fxHOhGp-4gT3gXqy6KHzq4,4852
 ddesigner_api/pytorch/__init__.py,sha256=292PDiVMURserkbbtdAT_VVorOkS8NlBF6gPQEefu4w,770
 ddesigner_api/pytorch/examples/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-ddesigner_api/pytorch/examples/examples_pytorch.py,sha256=erg2fZF-rGjqVfSztq7dEo7eIhSBafI6FAYxSnCYDnY,5016
+ddesigner_api/pytorch/examples/examples_pytorch.py,sha256=A5tIdMnUDQie4rrE1wJrd0oFfzZgOnq9evjaA0tLTf0,7416
 ddesigner_api/pytorch/xwn/__init__.py,sha256=RS2lQNf9O7p__G_wVfxtvBrw0TSf7YKB_LeTqzKUJ_M,736
-ddesigner_api/pytorch/xwn/torch_nn.py,sha256=mMEqihjLyE2ivrp9-BsPHfa4fvvyeCFg4mPbdv-Att0,63140
-ddesigner_api/pytorch/xwn/torch_opt.py,sha256=N1hVtCkEsdfi5OzV7RtsrQkV7N1ZLS_suJgEv8o6mPg,5030
+ddesigner_api/pytorch/xwn/torch_nn.py,sha256=Es4CL3qRmMBYMZRJBiwUwGoo49WVRlJiZHhwF3b1GH0,65337
+ddesigner_api/pytorch/xwn/torch_opt.py,sha256=zivpN7V0em7LkhaqZ078ZYTLdZMGt2t5alMohhnX5kY,5223
 ddesigner_api/tensorflow/__init__.py,sha256=q4RdbPLAQVOiRpf5H4WNGeTqWu8GbeW9gav3RFLev18,873
 ddesigner_api/tensorflow/dpi_blocks.py,sha256=cnpnga_thpaanblng9fZaV6mL_jlvx1IBJ1MXBH3bIk,11329
 ddesigner_api/tensorflow/dpi_layers.py,sha256=9MDHfltJ5brfRE7pQhKBE6mnfi3o2jEkvE64hv_IyQc,6208
 ddesigner_api/tensorflow/examples/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 ddesigner_api/tensorflow/examples/examples_keras.py,sha256=3icVGij_UymaEYkOwO4TZNRkWCBjLLSg-Khtlus_Fu8,7883
 ddesigner_api/tensorflow/examples/examples_tensorflow.py,sha256=HIwwuTR6WVR2raIAVY9rexO0Ex0iiby_jZ3l14r3jn8,3021
 ddesigner_api/tensorflow/xwn/__init__.py,sha256=raA9SRLD8OupFBsA2ujBA5xCPTYHS-EO7PYVPIRXL_0,790
 ddesigner_api/tensorflow/xwn/base_conv.py,sha256=9ZXF9lkGhxU8K1VX8NRfJstV1t94oqE3iw5PAH3xVwk,16322
 ddesigner_api/tensorflow/xwn/keras_layers.py,sha256=QRcXOLPDipoKRSxzZdOzbmboGDxcXaywUNyzL-cXEac,29451
 ddesigner_api/tensorflow/xwn/keras_opt.py,sha256=qZDPq4kaJ5cCz5QxqW5MSV9SpdNrm8TsalSbIAElBds,5013
 ddesigner_api/tensorflow/xwn/tf_nn.py,sha256=oaIXhbau-gtFyndce2dF3xWCDOpNhAwCJNLDkR5b5iU,9240
 ddesigner_api/tensorflow/xwn/tf_opt.py,sha256=Uz7-Q0pzC6z1gJkyMr1LRKxmXOgMAYlilj9Vwnaxn8k,4046
-DDesignerAPI-0.0.2.4.dist-info/LICENSE,sha256=BIg47KsjFz_m25s6T12eL1SAuGkt_KVW_tSqA5yga8g,9136
-DDesignerAPI-0.0.2.4.dist-info/METADATA,sha256=Ww4QKgNeIegPYeNwUkUwEgYVkWPTY2dv7zkd6qjWMkM,6269
-DDesignerAPI-0.0.2.4.dist-info/WHEEL,sha256=OqRkF0eY5GHssMorFjlbTIq072vpHpF60fIQA6lS9xA,92
-DDesignerAPI-0.0.2.4.dist-info/top_level.txt,sha256=qYDp5VPzyYyterLRCKrHqsvRLXTHSMOd-Xiwy2HJ_Ow,14
-DDesignerAPI-0.0.2.4.dist-info/RECORD,,
+DDesignerAPI-0.0.2.6.dist-info/LICENSE,sha256=BIg47KsjFz_m25s6T12eL1SAuGkt_KVW_tSqA5yga8g,9136
+DDesignerAPI-0.0.2.6.dist-info/METADATA,sha256=gug2fNuHSOGAxzmPWxToBnKaATGC_rpOtwisgDsukDs,6559
+DDesignerAPI-0.0.2.6.dist-info/WHEEL,sha256=OqRkF0eY5GHssMorFjlbTIq072vpHpF60fIQA6lS9xA,92
+DDesignerAPI-0.0.2.6.dist-info/top_level.txt,sha256=qYDp5VPzyYyterLRCKrHqsvRLXTHSMOd-Xiwy2HJ_Ow,14
+DDesignerAPI-0.0.2.6.dist-info/RECORD,,
```

