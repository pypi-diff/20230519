# Comparing `tmp/deep_training-0.1.5.post2-py3-none-any.whl.zip` & `tmp/deep_training-0.1.5.post3-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,187 +1,187 @@
-Zip file size: 345789 bytes, number of entries: 185
--rw-rw-rw-  2.0 fat       47 b- defN 23-Apr-10 11:44 deep_training/__init__.py
--rw-rw-rw-  2.0 fat      903 b- defN 23-May-16 11:12 deep_training/setup.py
--rw-rw-rw-  2.0 fat       55 b- defN 23-Apr-10 11:44 deep_training/cv/__init__.py
--rw-rw-rw-  2.0 fat      195 b- defN 23-Apr-10 11:44 deep_training/data_helper/__init__.py
--rw-rw-rw-  2.0 fat    17724 b- defN 23-May-02 04:53 deep_training/data_helper/data_helper.py
--rw-rw-rw-  2.0 fat     5041 b- defN 23-Apr-28 11:47 deep_training/data_helper/data_module.py
--rw-rw-rw-  2.0 fat    12121 b- defN 23-Apr-28 11:47 deep_training/data_helper/training_args.py
--rw-rw-rw-  2.0 fat       70 b- defN 23-Apr-10 11:44 deep_training/nlp/__init__.py
--rw-rw-rw-  2.0 fat       56 b- defN 23-Apr-10 11:44 deep_training/nlp/layers/__init__.py
--rw-rw-rw-  2.0 fat      241 b- defN 23-Apr-10 11:44 deep_training/nlp/layers/activate.py
--rw-rw-rw-  2.0 fat    13271 b- defN 23-Apr-10 11:44 deep_training/nlp/layers/crf.py
--rw-rw-rw-  2.0 fat     4653 b- defN 23-Apr-10 11:44 deep_training/nlp/layers/handshakingkernel.py
--rw-rw-rw-  2.0 fat      435 b- defN 23-Apr-10 11:44 deep_training/nlp/layers/mask.py
--rw-rw-rw-  2.0 fat     1319 b- defN 23-Apr-10 11:44 deep_training/nlp/layers/mhslayer.py
--rw-rw-rw-  2.0 fat     5911 b- defN 23-Apr-10 11:44 deep_training/nlp/layers/norm.py
--rw-rw-rw-  2.0 fat     1406 b- defN 23-Apr-28 11:47 deep_training/nlp/layers/ppo.py
--rw-rw-rw-  2.0 fat     1220 b- defN 23-Apr-10 11:44 deep_training/nlp/layers/prefix_encoder.py
--rw-rw-rw-  2.0 fat     7259 b- defN 23-Apr-10 11:44 deep_training/nlp/layers/seq_pointer.py
--rw-rw-rw-  2.0 fat     3550 b- defN 23-Apr-10 11:44 deep_training/nlp/layers/w2ner.py
--rw-rw-rw-  2.0 fat       72 b- defN 23-Apr-10 11:44 deep_training/nlp/layers/lora_v1/__init__.py
--rw-rw-rw-  2.0 fat    15095 b- defN 23-Apr-10 11:44 deep_training/nlp/layers/lora_v1/layers.py
--rw-rw-rw-  2.0 fat     1819 b- defN 23-Apr-10 11:44 deep_training/nlp/layers/lora_v1/utils.py
--rw-rw-rw-  2.0 fat       72 b- defN 23-Apr-10 15:59 deep_training/nlp/layers/lora_v2/__init__.py
--rw-rw-rw-  2.0 fat    15465 b- defN 23-Apr-11 15:24 deep_training/nlp/layers/lora_v2/adalora.py
--rw-rw-rw-  2.0 fat     8565 b- defN 23-Apr-11 15:24 deep_training/nlp/layers/lora_v2/layers.py
--rw-rw-rw-  2.0 fat     9287 b- defN 23-May-10 10:43 deep_training/nlp/layers/lora_v2/utils.py
--rw-rw-rw-  2.0 fat       80 b- defN 23-May-02 03:45 deep_training/nlp/layers/prompt/__init__.py
--rw-rw-rw-  2.0 fat    15541 b- defN 23-May-02 04:41 deep_training/nlp/layers/prompt/adaption_prompt.py
--rw-rw-rw-  2.0 fat     5463 b- defN 23-May-02 04:41 deep_training/nlp/layers/prompt/p_tuning.py
--rw-rw-rw-  2.0 fat     3053 b- defN 23-May-02 03:45 deep_training/nlp/layers/prompt/prefix_tuning.py
--rw-rw-rw-  2.0 fat     3523 b- defN 23-May-02 04:42 deep_training/nlp/layers/prompt/prompt_tuning.py
--rw-rw-rw-  2.0 fat     9285 b- defN 23-May-15 10:46 deep_training/nlp/layers/prompt/utils.py
--rw-rw-rw-  2.0 fat     3662 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/BatchAllTripletLoss.py
--rw-rw-rw-  2.0 fat     3880 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/BatchHardSoftMarginTripletLoss.py
--rw-rw-rw-  2.0 fat     8358 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/BatchHardTripletLoss.py
--rw-rw-rw-  2.0 fat     4552 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/BatchSemiHardTripletLoss.py
--rw-rw-rw-  2.0 fat     2255 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/ContrastiveLoss.py
--rw-rw-rw-  2.0 fat     4573 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/ContrastiveTensionLoss.py
--rw-rw-rw-  2.0 fat     1359 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/CosineSimilarityLoss.py
--rw-rw-rw-  2.0 fat      742 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/MSELoss.py
--rw-rw-rw-  2.0 fat     1315 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/MarginMSELoss.py
--rw-rw-rw-  2.0 fat     5302 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/MegaBatchMarginLoss.py
--rw-rw-rw-  2.0 fat     2420 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/MultipleNegativesRankingLoss.py
--rw-rw-rw-  2.0 fat     2905 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/MultipleNegativesSymmetricRankingLoss.py
--rw-rw-rw-  2.0 fat     1863 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/OnlineContrastiveLoss.py
--rw-rw-rw-  2.0 fat     2880 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/SoftmaxLoss.py
--rw-rw-rw-  2.0 fat     2306 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/TripletLoss.py
--rw-rw-rw-  2.0 fat      599 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/__init__.py
--rw-rw-rw-  2.0 fat      661 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/bce_loss.py
--rw-rw-rw-  2.0 fat     1397 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/center_loss.py
--rw-rw-rw-  2.0 fat     1772 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/circle_loss.py
--rw-rw-rw-  2.0 fat     1056 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/contrast.py
--rw-rw-rw-  2.0 fat      619 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/dice_loss.py
--rw-rw-rw-  2.0 fat      710 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/focal_loss.py
--rw-rw-rw-  2.0 fat      882 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/label_smoothing.py
--rw-rw-rw-  2.0 fat      547 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/lm_loss.py
--rw-rw-rw-  2.0 fat     2149 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/loss_arcface.py
--rw-rw-rw-  2.0 fat      962 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/loss_casrel.py
--rw-rw-rw-  2.0 fat     1496 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/loss_cosent.py
--rw-rw-rw-  2.0 fat     1912 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/loss_cosface.py
--rw-rw-rw-  2.0 fat     2223 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/loss_globalpointer.py
--rw-rw-rw-  2.0 fat     6020 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/loss_infonce.py
--rw-rw-rw-  2.0 fat      884 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/loss_kl.py
--rw-rw-rw-  2.0 fat     1270 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/loss_mhslinker.py
--rw-rw-rw-  2.0 fat      617 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/loss_r-drop.py
--rw-rw-rw-  2.0 fat     2656 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/loss_sphereface.py
--rw-rw-rw-  2.0 fat      562 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/loss_splinker.py
--rw-rw-rw-  2.0 fat    10822 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/loss_spn4re.py
--rw-rw-rw-  2.0 fat     5644 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/loss_tplinker.py
--rw-rw-rw-  2.0 fat     2466 b- defN 23-Apr-10 11:44 deep_training/nlp/losses/utils.py
--rw-rw-rw-  2.0 fat       71 b- defN 23-Apr-10 11:44 deep_training/nlp/metrics/__init__.py
--rw-rw-rw-  2.0 fat      655 b- defN 23-Apr-10 11:44 deep_training/nlp/metrics/pointer.py
--rw-rw-rw-  2.0 fat       58 b- defN 23-Apr-10 11:44 deep_training/nlp/models/__init__.py
--rw-rw-rw-  2.0 fat     6826 b- defN 23-Apr-28 11:47 deep_training/nlp/models/casrel.py
--rw-rw-rw-  2.0 fat     5093 b- defN 23-Apr-28 11:47 deep_training/nlp/models/crf_cascad.py
--rw-rw-rw-  2.0 fat     1588 b- defN 23-Apr-28 11:47 deep_training/nlp/models/crf_model.py
--rw-rw-rw-  2.0 fat    12985 b- defN 23-Apr-28 11:47 deep_training/nlp/models/diffcse.py
--rw-rw-rw-  2.0 fat     5395 b- defN 23-Apr-28 11:47 deep_training/nlp/models/esimcse.py
--rw-rw-rw-  2.0 fat     4209 b- defN 23-Apr-28 11:47 deep_training/nlp/models/gec_model.py
--rw-rw-rw-  2.0 fat    10854 b- defN 23-Apr-28 11:47 deep_training/nlp/models/gplinker.py
--rw-rw-rw-  2.0 fat     3814 b- defN 23-Apr-28 11:47 deep_training/nlp/models/infonce.py
--rw-rw-rw-  2.0 fat     2459 b- defN 23-Apr-28 11:47 deep_training/nlp/models/mhs_ner.py
--rw-rw-rw-  2.0 fat     5991 b- defN 23-Apr-28 11:47 deep_training/nlp/models/mhslinker.py
--rw-rw-rw-  2.0 fat     4661 b- defN 23-Apr-28 11:47 deep_training/nlp/models/onerel_model.py
--rw-rw-rw-  2.0 fat     2750 b- defN 23-Apr-28 11:47 deep_training/nlp/models/pointer.py
--rw-rw-rw-  2.0 fat    13392 b- defN 23-Apr-28 11:47 deep_training/nlp/models/prefixtuning.py
--rw-rw-rw-  2.0 fat    15915 b- defN 23-Apr-28 11:47 deep_training/nlp/models/prgc_model.py
--rw-rw-rw-  2.0 fat    16115 b- defN 23-Apr-28 11:47 deep_training/nlp/models/promptbert_cse.py
--rw-rw-rw-  2.0 fat     5149 b- defN 23-Apr-28 11:47 deep_training/nlp/models/pure_model.py
--rw-rw-rw-  2.0 fat     3949 b- defN 23-Apr-28 11:47 deep_training/nlp/models/simcse.py
--rw-rw-rw-  2.0 fat     6022 b- defN 23-Apr-28 11:47 deep_training/nlp/models/span_ner.py
--rw-rw-rw-  2.0 fat    14454 b- defN 23-Apr-28 11:47 deep_training/nlp/models/spn4re.py
--rw-rw-rw-  2.0 fat    11383 b- defN 23-Apr-28 11:47 deep_training/nlp/models/tplinker.py
--rw-rw-rw-  2.0 fat     8157 b- defN 23-Apr-28 11:47 deep_training/nlp/models/tplinkerplus.py
--rw-rw-rw-  2.0 fat     6624 b- defN 23-Apr-28 11:47 deep_training/nlp/models/transformer.py
--rw-rw-rw-  2.0 fat    26238 b- defN 23-May-08 15:45 deep_training/nlp/models/transformer_base.py
--rw-rw-rw-  2.0 fat     7968 b- defN 23-Apr-28 11:47 deep_training/nlp/models/tsdae_model.py
--rw-rw-rw-  2.0 fat     9040 b- defN 23-Apr-28 11:47 deep_training/nlp/models/w2ner.py
--rw-rw-rw-  2.0 fat    16524 b- defN 23-Apr-28 11:47 deep_training/nlp/models/LLaMA/__init__.py
--rw-rw-rw-  2.0 fat     5087 b- defN 23-Apr-10 11:44 deep_training/nlp/models/LLaMA/configuration.py
--rw-rw-rw-  2.0 fat    19207 b- defN 23-Apr-28 11:47 deep_training/nlp/models/LLaMA_parallel/__init__.py
--rw-rw-rw-  2.0 fat     5087 b- defN 23-Apr-10 11:44 deep_training/nlp/models/LLaMA_parallel/configuration.py
--rw-rw-rw-  2.0 fat    31627 b- defN 23-Apr-10 11:44 deep_training/nlp/models/PaLM/__init__.py
--rw-rw-rw-  2.0 fat     5890 b- defN 23-Apr-10 11:44 deep_training/nlp/models/PaLM/configuration.py
--rw-rw-rw-  2.0 fat    60510 b- defN 23-May-02 03:45 deep_training/nlp/models/chatglm/__init__.py
--rw-rw-rw-  2.0 fat     4575 b- defN 23-Apr-10 11:44 deep_training/nlp/models/chatglm/configuration.py
--rw-rw-rw-  2.0 fat    15150 b- defN 23-Apr-10 11:44 deep_training/nlp/models/chatglm/quantization.py
--rw-rw-rw-  2.0 fat    17037 b- defN 23-May-12 10:48 deep_training/nlp/models/chatglm/tokenization.py
--rw-rw-rw-  2.0 fat    34123 b- defN 23-Apr-10 11:44 deep_training/nlp/models/laMDA/__init__.py
--rw-rw-rw-  2.0 fat     5981 b- defN 23-Apr-10 11:44 deep_training/nlp/models/laMDA/configuration.py
--rw-rw-rw-  2.0 fat      181 b- defN 23-Apr-11 10:52 deep_training/nlp/models/lora/__init__.py
--rw-rw-rw-  2.0 fat      123 b- defN 23-Apr-10 16:34 deep_training/nlp/models/lora/v1/__init__.py
--rw-rw-rw-  2.0 fat     7054 b- defN 23-Apr-10 11:44 deep_training/nlp/models/lora/v1/configuration.py
--rw-rw-rw-  2.0 fat    13688 b- defN 23-May-02 06:57 deep_training/nlp/models/lora/v1/lora_wrapper.py
--rw-rw-rw-  2.0 fat      206 b- defN 23-Apr-11 10:52 deep_training/nlp/models/lora/v2/__init__.py
--rw-rw-rw-  2.0 fat    13112 b- defN 23-Apr-10 16:38 deep_training/nlp/models/lora/v2/adalora_model.py
--rw-rw-rw-  2.0 fat    11285 b- defN 23-Apr-28 11:47 deep_training/nlp/models/lora/v2/configuration.py
--rw-rw-rw-  2.0 fat    11745 b- defN 23-Apr-18 11:05 deep_training/nlp/models/lora/v2/lora_model.py
--rw-rw-rw-  2.0 fat    10644 b- defN 23-May-08 15:03 deep_training/nlp/models/lora/v2/lora_wrapper.py
--rw-rw-rw-  2.0 fat     4889 b- defN 23-Apr-10 12:59 deep_training/nlp/models/lora/v2/save_and_load.py
--rw-rw-rw-  2.0 fat      467 b- defN 23-Apr-28 11:47 deep_training/nlp/models/moss/__init__.py
--rw-rw-rw-  2.0 fat     5097 b- defN 23-Apr-28 11:47 deep_training/nlp/models/moss/configuration_moss.py
--rw-rw-rw-  2.0 fat     6735 b- defN 23-Apr-28 11:47 deep_training/nlp/models/moss/custom_autotune.py
--rw-rw-rw-  2.0 fat    31079 b- defN 23-Apr-28 11:47 deep_training/nlp/models/moss/modeling_moss.py
--rw-rw-rw-  2.0 fat    18773 b- defN 23-May-15 10:46 deep_training/nlp/models/moss/quantization.py
--rw-rw-rw-  2.0 fat    15939 b- defN 23-May-02 17:44 deep_training/nlp/models/moss/tokenization_moss.py
--rw-rw-rw-  2.0 fat      203 b- defN 23-May-02 06:07 deep_training/nlp/models/prompt/__init__.py
--rw-rw-rw-  2.0 fat    12062 b- defN 23-May-02 16:25 deep_training/nlp/models/prompt/configuration.py
--rw-rw-rw-  2.0 fat    52124 b- defN 23-May-15 10:46 deep_training/nlp/models/prompt/prompt_model.py
--rw-rw-rw-  2.0 fat     3551 b- defN 23-May-02 15:49 deep_training/nlp/models/prompt/save_and_load.py
--rw-rw-rw-  2.0 fat     1917 b- defN 23-May-02 05:50 deep_training/nlp/models/prompt/utils.py
--rw-rw-rw-  2.0 fat       54 b- defN 23-May-11 10:55 deep_training/nlp/models/rl/__init__.py
--rw-rw-rw-  2.0 fat      272 b- defN 23-May-13 09:46 deep_training/nlp/models/rl/modeling.py
--rw-rw-rw-  2.0 fat    20838 b- defN 23-May-16 10:52 deep_training/nlp/models/rl/modeling_ilql.py
--rw-rw-rw-  2.0 fat    41532 b- defN 23-May-13 11:48 deep_training/nlp/models/rl/modeling_ppo.py
--rw-rw-rw-  2.0 fat     8026 b- defN 23-May-11 10:55 deep_training/nlp/models/rl/utils.py
--rw-rw-rw-  2.0 fat      102 b- defN 23-Apr-10 11:44 deep_training/nlp/models/splinker/__init__.py
--rw-rw-rw-  2.0 fat     2866 b- defN 23-Apr-28 11:47 deep_training/nlp/models/splinker/splinker.py
--rw-rw-rw-  2.0 fat    14478 b- defN 23-Apr-10 11:44 deep_training/nlp/models/t5decoder/__init__.py
--rw-rw-rw-  2.0 fat     6646 b- defN 23-Apr-10 11:44 deep_training/nlp/models/t5encoder/__init__.py
--rw-rw-rw-  2.0 fat       56 b- defN 23-Apr-10 11:44 deep_training/nlp/optimizer/__init__.py
--rw-rw-rw-  2.0 fat     5225 b- defN 23-Apr-10 11:44 deep_training/nlp/optimizer/lamb.py
--rw-rw-rw-  2.0 fat       99 b- defN 23-Apr-10 11:44 deep_training/nlp/optimizer/lion/__init__.py
--rw-rw-rw-  2.0 fat     2516 b- defN 23-May-10 10:43 deep_training/nlp/optimizer/lion/lion.py
--rw-rw-rw-  2.0 fat     2499 b- defN 23-May-10 10:43 deep_training/nlp/optimizer/lion/triton.py
--rw-rw-rw-  2.0 fat       79 b- defN 23-Apr-28 11:47 deep_training/nlp/rl/__init__.py
--rw-rw-rw-  2.0 fat       88 b- defN 23-May-13 15:15 deep_training/nlp/rl/ilql/__init__.py
--rw-rw-rw-  2.0 fat     2232 b- defN 23-May-16 10:52 deep_training/nlp/rl/ilql/configuration.py
--rw-rw-rw-  2.0 fat     3691 b- defN 23-May-14 15:37 deep_training/nlp/rl/ilql/data_define.py
--rw-rw-rw-  2.0 fat     7800 b- defN 23-May-15 10:46 deep_training/nlp/rl/ilql/ilql_dataset.py
--rw-rw-rw-  2.0 fat     6244 b- defN 23-May-16 10:52 deep_training/nlp/rl/ilql/ilql_module.py
--rw-rw-rw-  2.0 fat    35681 b- defN 23-May-16 11:20 deep_training/nlp/rl/ilql/ilql_trainer.py
--rw-rw-rw-  2.0 fat       55 b- defN 23-Apr-28 11:47 deep_training/nlp/rl/ppo/__init__.py
--rw-rw-rw-  2.0 fat     3460 b- defN 23-May-14 14:18 deep_training/nlp/rl/ppo/configuration.py
--rw-rw-rw-  2.0 fat     3201 b- defN 23-May-14 15:23 deep_training/nlp/rl/ppo/data_define.py
--rw-rw-rw-  2.0 fat     3344 b- defN 23-May-14 15:23 deep_training/nlp/rl/ppo/ppo_dataset.py
--rw-rw-rw-  2.0 fat    10103 b- defN 23-May-15 10:46 deep_training/nlp/rl/ppo/ppo_module.py
--rw-rw-rw-  2.0 fat    47376 b- defN 23-May-16 11:20 deep_training/nlp/rl/ppo/ppo_trainer.py
--rw-rw-rw-  2.0 fat       88 b- defN 23-May-13 15:38 deep_training/nlp/rl/rl_base/__init__.py
--rw-rw-rw-  2.0 fat     3724 b- defN 23-May-14 15:23 deep_training/nlp/rl/rl_base/rl_dataset.py
--rw-rw-rw-  2.0 fat    10700 b- defN 23-May-14 14:18 deep_training/nlp/rl/utils/__init__.py
--rw-rw-rw-  2.0 fat     3529 b- defN 23-May-13 15:29 deep_training/nlp/rl/utils/configuration.py
--rw-rw-rw-  2.0 fat     9844 b- defN 23-May-08 10:49 deep_training/nlp/rl/utils/logging.py
--rw-rw-rw-  2.0 fat     2868 b- defN 23-Apr-10 11:44 deep_training/nlp/scheduler/__init__.py
--rw-rw-rw-  2.0 fat     7056 b- defN 23-May-16 11:09 deep_training/nlp/utils/__init__.py
--rw-rw-rw-  2.0 fat     6323 b- defN 23-Apr-10 11:44 deep_training/nlp/utils/adversarial.py
--rw-rw-rw-  2.0 fat    15256 b- defN 23-Apr-10 11:44 deep_training/nlp/utils/nlputils.py
--rw-rw-rw-  2.0 fat      795 b- defN 23-Apr-10 11:44 deep_training/nlp/utils/spearman.py
--rw-rw-rw-  2.0 fat       53 b- defN 23-Apr-10 11:44 deep_training/tfnlp/__init__.py
--rw-rw-rw-  2.0 fat       53 b- defN 23-Apr-10 11:44 deep_training/tfnlp/layers/__init__.py
--rw-rw-rw-  2.0 fat       53 b- defN 23-Apr-10 11:44 deep_training/tfnlp/losses/__init__.py
--rw-rw-rw-  2.0 fat       53 b- defN 23-Apr-10 11:44 deep_training/tfnlp/metrics/__init__.py
--rw-rw-rw-  2.0 fat       53 b- defN 23-Apr-10 11:44 deep_training/tfnlp/models/__init__.py
--rw-rw-rw-  2.0 fat       53 b- defN 23-Apr-10 11:44 deep_training/tfnlp/optimizer/__init__.py
--rw-rw-rw-  2.0 fat       53 b- defN 23-Apr-10 11:44 deep_training/tfnlp/scheduler/__init__.py
--rw-rw-rw-  2.0 fat       53 b- defN 23-Apr-10 11:44 deep_training/tfnlp/utils/__init__.py
--rw-rw-rw-  2.0 fat       55 b- defN 23-Apr-10 11:44 deep_training/utils/__init__.py
--rw-rw-rw-  2.0 fat     1941 b- defN 23-Apr-10 11:44 deep_training/utils/distributed.py
--rw-rw-rw-  2.0 fat     1724 b- defN 23-Apr-10 11:44 deep_training/utils/func.py
--rw-rw-rw-  2.0 fat     5117 b- defN 23-Apr-10 11:44 deep_training/utils/maskedlm.py
--rw-rw-rw-  2.0 fat    14500 b- defN 23-May-10 15:00 deep_training/utils/trainer.py
--rw-rw-rw-  2.0 fat      588 b- defN 23-May-16 11:23 deep_training-0.1.5.post2.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 23-May-16 11:23 deep_training-0.1.5.post2.dist-info/WHEEL
--rw-rw-rw-  2.0 fat       14 b- defN 23-May-16 11:23 deep_training-0.1.5.post2.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat    17964 b- defN 23-May-16 11:23 deep_training-0.1.5.post2.dist-info/RECORD
-185 files, 1243747 bytes uncompressed, 316685 bytes compressed:  74.5%
+Zip file size: 345981 bytes, number of entries: 185
+-rw-rw-rw-  2.0 fat       47 b- defN 23-Mar-22 07:43 deep_training/__init__.py
+-rw-rw-rw-  2.0 fat      903 b- defN 23-May-19 04:14 deep_training/setup.py
+-rw-rw-rw-  2.0 fat       55 b- defN 22-Dec-09 05:30 deep_training/cv/__init__.py
+-rw-rw-rw-  2.0 fat      195 b- defN 23-Jan-29 01:07 deep_training/data_helper/__init__.py
+-rw-rw-rw-  2.0 fat    17724 b- defN 23-May-04 00:28 deep_training/data_helper/data_helper.py
+-rw-rw-rw-  2.0 fat     5041 b- defN 23-Apr-28 06:13 deep_training/data_helper/data_module.py
+-rw-rw-rw-  2.0 fat    12121 b- defN 23-Apr-27 00:33 deep_training/data_helper/training_args.py
+-rw-rw-rw-  2.0 fat       70 b- defN 22-Dec-13 03:17 deep_training/nlp/__init__.py
+-rw-rw-rw-  2.0 fat       56 b- defN 22-Nov-10 08:28 deep_training/nlp/layers/__init__.py
+-rw-rw-rw-  2.0 fat      241 b- defN 23-Mar-13 05:48 deep_training/nlp/layers/activate.py
+-rw-rw-rw-  2.0 fat    13271 b- defN 22-Nov-14 00:17 deep_training/nlp/layers/crf.py
+-rw-rw-rw-  2.0 fat     4653 b- defN 22-Dec-12 00:12 deep_training/nlp/layers/handshakingkernel.py
+-rw-rw-rw-  2.0 fat      435 b- defN 22-Dec-02 00:22 deep_training/nlp/layers/mask.py
+-rw-rw-rw-  2.0 fat     1319 b- defN 22-Dec-12 00:12 deep_training/nlp/layers/mhslayer.py
+-rw-rw-rw-  2.0 fat     5911 b- defN 22-Dec-08 00:08 deep_training/nlp/layers/norm.py
+-rw-rw-rw-  2.0 fat     1406 b- defN 23-Apr-28 00:24 deep_training/nlp/layers/ppo.py
+-rw-rw-rw-  2.0 fat     1220 b- defN 22-Jul-21 00:57 deep_training/nlp/layers/prefix_encoder.py
+-rw-rw-rw-  2.0 fat     7259 b- defN 22-Dec-14 02:36 deep_training/nlp/layers/seq_pointer.py
+-rw-rw-rw-  2.0 fat     3550 b- defN 22-Dec-15 00:57 deep_training/nlp/layers/w2ner.py
+-rw-rw-rw-  2.0 fat       72 b- defN 23-Apr-11 00:30 deep_training/nlp/layers/lora_v1/__init__.py
+-rw-rw-rw-  2.0 fat    15095 b- defN 23-Apr-11 00:30 deep_training/nlp/layers/lora_v1/layers.py
+-rw-rw-rw-  2.0 fat     1819 b- defN 23-Apr-11 00:30 deep_training/nlp/layers/lora_v1/utils.py
+-rw-rw-rw-  2.0 fat       72 b- defN 23-Apr-11 00:30 deep_training/nlp/layers/lora_v2/__init__.py
+-rw-rw-rw-  2.0 fat    15465 b- defN 23-Apr-12 00:34 deep_training/nlp/layers/lora_v2/adalora.py
+-rw-rw-rw-  2.0 fat     8565 b- defN 23-Apr-12 00:34 deep_training/nlp/layers/lora_v2/layers.py
+-rw-rw-rw-  2.0 fat     9287 b- defN 23-May-10 01:12 deep_training/nlp/layers/lora_v2/utils.py
+-rw-rw-rw-  2.0 fat       80 b- defN 23-May-04 00:28 deep_training/nlp/layers/prompt/__init__.py
+-rw-rw-rw-  2.0 fat    15541 b- defN 23-May-04 00:28 deep_training/nlp/layers/prompt/adaption_prompt.py
+-rw-rw-rw-  2.0 fat     5463 b- defN 23-May-04 00:28 deep_training/nlp/layers/prompt/p_tuning.py
+-rw-rw-rw-  2.0 fat     3053 b- defN 23-May-04 00:28 deep_training/nlp/layers/prompt/prefix_tuning.py
+-rw-rw-rw-  2.0 fat     3523 b- defN 23-May-04 00:28 deep_training/nlp/layers/prompt/prompt_tuning.py
+-rw-rw-rw-  2.0 fat     9285 b- defN 23-May-15 05:41 deep_training/nlp/layers/prompt/utils.py
+-rw-rw-rw-  2.0 fat     3662 b- defN 22-Nov-16 07:15 deep_training/nlp/losses/BatchAllTripletLoss.py
+-rw-rw-rw-  2.0 fat     3880 b- defN 22-Nov-16 07:15 deep_training/nlp/losses/BatchHardSoftMarginTripletLoss.py
+-rw-rw-rw-  2.0 fat     8358 b- defN 22-Nov-16 07:15 deep_training/nlp/losses/BatchHardTripletLoss.py
+-rw-rw-rw-  2.0 fat     4552 b- defN 22-Nov-16 07:15 deep_training/nlp/losses/BatchSemiHardTripletLoss.py
+-rw-rw-rw-  2.0 fat     2255 b- defN 22-Nov-18 01:05 deep_training/nlp/losses/ContrastiveLoss.py
+-rw-rw-rw-  2.0 fat     4573 b- defN 22-Nov-16 07:04 deep_training/nlp/losses/ContrastiveTensionLoss.py
+-rw-rw-rw-  2.0 fat     1359 b- defN 22-Nov-16 07:15 deep_training/nlp/losses/CosineSimilarityLoss.py
+-rw-rw-rw-  2.0 fat      742 b- defN 22-Nov-16 07:15 deep_training/nlp/losses/MSELoss.py
+-rw-rw-rw-  2.0 fat     1315 b- defN 22-Nov-16 07:15 deep_training/nlp/losses/MarginMSELoss.py
+-rw-rw-rw-  2.0 fat     5302 b- defN 22-Nov-16 07:11 deep_training/nlp/losses/MegaBatchMarginLoss.py
+-rw-rw-rw-  2.0 fat     2420 b- defN 23-Jan-18 08:08 deep_training/nlp/losses/MultipleNegativesRankingLoss.py
+-rw-rw-rw-  2.0 fat     2905 b- defN 22-Nov-16 07:11 deep_training/nlp/losses/MultipleNegativesSymmetricRankingLoss.py
+-rw-rw-rw-  2.0 fat     1863 b- defN 22-Nov-16 07:15 deep_training/nlp/losses/OnlineContrastiveLoss.py
+-rw-rw-rw-  2.0 fat     2880 b- defN 22-Nov-16 07:15 deep_training/nlp/losses/SoftmaxLoss.py
+-rw-rw-rw-  2.0 fat     2306 b- defN 22-Nov-16 07:15 deep_training/nlp/losses/TripletLoss.py
+-rw-rw-rw-  2.0 fat      599 b- defN 22-Nov-17 00:20 deep_training/nlp/losses/__init__.py
+-rw-rw-rw-  2.0 fat      661 b- defN 22-Dec-02 08:50 deep_training/nlp/losses/bce_loss.py
+-rw-rw-rw-  2.0 fat     1397 b- defN 22-Nov-17 05:38 deep_training/nlp/losses/center_loss.py
+-rw-rw-rw-  2.0 fat     1772 b- defN 22-Nov-17 07:28 deep_training/nlp/losses/circle_loss.py
+-rw-rw-rw-  2.0 fat     1056 b- defN 23-Jan-13 07:26 deep_training/nlp/losses/contrast.py
+-rw-rw-rw-  2.0 fat      619 b- defN 22-Aug-22 01:11 deep_training/nlp/losses/dice_loss.py
+-rw-rw-rw-  2.0 fat      710 b- defN 22-Nov-16 06:49 deep_training/nlp/losses/focal_loss.py
+-rw-rw-rw-  2.0 fat      882 b- defN 22-Aug-22 01:11 deep_training/nlp/losses/label_smoothing.py
+-rw-rw-rw-  2.0 fat      547 b- defN 23-Jan-29 01:07 deep_training/nlp/losses/lm_loss.py
+-rw-rw-rw-  2.0 fat     2149 b- defN 22-Dec-29 06:05 deep_training/nlp/losses/loss_arcface.py
+-rw-rw-rw-  2.0 fat      962 b- defN 22-Dec-05 00:45 deep_training/nlp/losses/loss_casrel.py
+-rw-rw-rw-  2.0 fat     1496 b- defN 22-Dec-21 00:45 deep_training/nlp/losses/loss_cosent.py
+-rw-rw-rw-  2.0 fat     1912 b- defN 22-Dec-29 06:03 deep_training/nlp/losses/loss_cosface.py
+-rw-rw-rw-  2.0 fat     2223 b- defN 22-Dec-08 00:49 deep_training/nlp/losses/loss_globalpointer.py
+-rw-rw-rw-  2.0 fat     6020 b- defN 23-Jan-09 00:29 deep_training/nlp/losses/loss_infonce.py
+-rw-rw-rw-  2.0 fat      884 b- defN 22-Dec-23 00:05 deep_training/nlp/losses/loss_kl.py
+-rw-rw-rw-  2.0 fat     1270 b- defN 23-Mar-14 03:03 deep_training/nlp/losses/loss_mhslinker.py
+-rw-rw-rw-  2.0 fat      617 b- defN 22-Dec-14 08:37 deep_training/nlp/losses/loss_r-drop.py
+-rw-rw-rw-  2.0 fat     2656 b- defN 22-Dec-29 06:04 deep_training/nlp/losses/loss_sphereface.py
+-rw-rw-rw-  2.0 fat      562 b- defN 22-Nov-25 06:44 deep_training/nlp/losses/loss_splinker.py
+-rw-rw-rw-  2.0 fat    10822 b- defN 23-Jan-09 09:00 deep_training/nlp/losses/loss_spn4re.py
+-rw-rw-rw-  2.0 fat     5644 b- defN 22-Dec-12 00:12 deep_training/nlp/losses/loss_tplinker.py
+-rw-rw-rw-  2.0 fat     2466 b- defN 23-Jan-18 09:12 deep_training/nlp/losses/utils.py
+-rw-rw-rw-  2.0 fat       71 b- defN 22-Dec-13 03:17 deep_training/nlp/metrics/__init__.py
+-rw-rw-rw-  2.0 fat      655 b- defN 22-Dec-02 00:22 deep_training/nlp/metrics/pointer.py
+-rw-rw-rw-  2.0 fat       58 b- defN 22-Nov-22 08:00 deep_training/nlp/models/__init__.py
+-rw-rw-rw-  2.0 fat     6826 b- defN 23-Apr-25 03:34 deep_training/nlp/models/casrel.py
+-rw-rw-rw-  2.0 fat     5093 b- defN 23-Apr-25 03:34 deep_training/nlp/models/crf_cascad.py
+-rw-rw-rw-  2.0 fat     1588 b- defN 23-Apr-25 03:34 deep_training/nlp/models/crf_model.py
+-rw-rw-rw-  2.0 fat    12985 b- defN 23-Apr-25 03:34 deep_training/nlp/models/diffcse.py
+-rw-rw-rw-  2.0 fat     5395 b- defN 23-Apr-27 00:33 deep_training/nlp/models/esimcse.py
+-rw-rw-rw-  2.0 fat     4209 b- defN 23-Apr-25 03:34 deep_training/nlp/models/gec_model.py
+-rw-rw-rw-  2.0 fat    10854 b- defN 23-Apr-25 03:34 deep_training/nlp/models/gplinker.py
+-rw-rw-rw-  2.0 fat     3814 b- defN 23-Apr-25 03:34 deep_training/nlp/models/infonce.py
+-rw-rw-rw-  2.0 fat     2459 b- defN 23-Apr-25 03:34 deep_training/nlp/models/mhs_ner.py
+-rw-rw-rw-  2.0 fat     5991 b- defN 23-Apr-25 03:34 deep_training/nlp/models/mhslinker.py
+-rw-rw-rw-  2.0 fat     4661 b- defN 23-Apr-25 03:34 deep_training/nlp/models/onerel_model.py
+-rw-rw-rw-  2.0 fat     2750 b- defN 23-Apr-25 03:34 deep_training/nlp/models/pointer.py
+-rw-rw-rw-  2.0 fat    13392 b- defN 23-Apr-25 03:34 deep_training/nlp/models/prefixtuning.py
+-rw-rw-rw-  2.0 fat    15915 b- defN 23-Apr-25 03:34 deep_training/nlp/models/prgc_model.py
+-rw-rw-rw-  2.0 fat    16115 b- defN 23-Apr-25 03:34 deep_training/nlp/models/promptbert_cse.py
+-rw-rw-rw-  2.0 fat     5149 b- defN 23-Apr-25 03:34 deep_training/nlp/models/pure_model.py
+-rw-rw-rw-  2.0 fat     3949 b- defN 23-Apr-25 03:34 deep_training/nlp/models/simcse.py
+-rw-rw-rw-  2.0 fat     6022 b- defN 23-Apr-25 03:34 deep_training/nlp/models/span_ner.py
+-rw-rw-rw-  2.0 fat    14454 b- defN 23-Apr-25 03:34 deep_training/nlp/models/spn4re.py
+-rw-rw-rw-  2.0 fat    11383 b- defN 23-Apr-25 03:34 deep_training/nlp/models/tplinker.py
+-rw-rw-rw-  2.0 fat     8157 b- defN 23-Apr-25 03:34 deep_training/nlp/models/tplinkerplus.py
+-rw-rw-rw-  2.0 fat     6624 b- defN 23-Apr-25 03:34 deep_training/nlp/models/transformer.py
+-rw-rw-rw-  2.0 fat    26238 b- defN 23-May-16 08:28 deep_training/nlp/models/transformer_base.py
+-rw-rw-rw-  2.0 fat     7968 b- defN 23-Apr-25 03:34 deep_training/nlp/models/tsdae_model.py
+-rw-rw-rw-  2.0 fat     9040 b- defN 23-Apr-25 03:34 deep_training/nlp/models/w2ner.py
+-rw-rw-rw-  2.0 fat    16524 b- defN 23-Apr-28 07:32 deep_training/nlp/models/LLaMA/__init__.py
+-rw-rw-rw-  2.0 fat     5087 b- defN 23-Mar-13 01:04 deep_training/nlp/models/LLaMA/configuration.py
+-rw-rw-rw-  2.0 fat    19207 b- defN 23-Apr-28 07:32 deep_training/nlp/models/LLaMA_parallel/__init__.py
+-rw-rw-rw-  2.0 fat     5087 b- defN 23-Mar-10 00:30 deep_training/nlp/models/LLaMA_parallel/configuration.py
+-rw-rw-rw-  2.0 fat    31627 b- defN 23-Mar-13 06:15 deep_training/nlp/models/PaLM/__init__.py
+-rw-rw-rw-  2.0 fat     5890 b- defN 23-Mar-13 06:15 deep_training/nlp/models/PaLM/configuration.py
+-rw-rw-rw-  2.0 fat    60510 b- defN 23-May-04 00:28 deep_training/nlp/models/chatglm/__init__.py
+-rw-rw-rw-  2.0 fat     4575 b- defN 23-Apr-10 00:42 deep_training/nlp/models/chatglm/configuration.py
+-rw-rw-rw-  2.0 fat    15150 b- defN 23-Apr-03 00:32 deep_training/nlp/models/chatglm/quantization.py
+-rw-rw-rw-  2.0 fat    17037 b- defN 23-May-12 07:25 deep_training/nlp/models/chatglm/tokenization.py
+-rw-rw-rw-  2.0 fat    34123 b- defN 23-Mar-13 06:18 deep_training/nlp/models/laMDA/__init__.py
+-rw-rw-rw-  2.0 fat     5981 b- defN 23-Mar-13 06:15 deep_training/nlp/models/laMDA/configuration.py
+-rw-rw-rw-  2.0 fat      181 b- defN 23-Apr-11 07:19 deep_training/nlp/models/lora/__init__.py
+-rw-rw-rw-  2.0 fat      123 b- defN 23-Apr-11 00:30 deep_training/nlp/models/lora/v1/__init__.py
+-rw-rw-rw-  2.0 fat     7054 b- defN 23-Apr-11 00:30 deep_training/nlp/models/lora/v1/configuration.py
+-rw-rw-rw-  2.0 fat    13688 b- defN 23-May-04 00:28 deep_training/nlp/models/lora/v1/lora_wrapper.py
+-rw-rw-rw-  2.0 fat      206 b- defN 23-Apr-11 01:58 deep_training/nlp/models/lora/v2/__init__.py
+-rw-rw-rw-  2.0 fat    13112 b- defN 23-Apr-11 00:30 deep_training/nlp/models/lora/v2/adalora_model.py
+-rw-rw-rw-  2.0 fat    11285 b- defN 23-Apr-26 08:14 deep_training/nlp/models/lora/v2/configuration.py
+-rw-rw-rw-  2.0 fat    11745 b- defN 23-Apr-18 01:24 deep_training/nlp/models/lora/v2/lora_model.py
+-rw-rw-rw-  2.0 fat    10644 b- defN 23-May-09 00:34 deep_training/nlp/models/lora/v2/lora_wrapper.py
+-rw-rw-rw-  2.0 fat     4889 b- defN 23-Apr-11 00:30 deep_training/nlp/models/lora/v2/save_and_load.py
+-rw-rw-rw-  2.0 fat      467 b- defN 23-Apr-21 04:29 deep_training/nlp/models/moss/__init__.py
+-rw-rw-rw-  2.0 fat     5097 b- defN 23-Apr-23 01:11 deep_training/nlp/models/moss/configuration_moss.py
+-rw-rw-rw-  2.0 fat     6735 b- defN 23-Apr-23 01:05 deep_training/nlp/models/moss/custom_autotune.py
+-rw-rw-rw-  2.0 fat    31079 b- defN 23-Apr-23 02:08 deep_training/nlp/models/moss/modeling_moss.py
+-rw-rw-rw-  2.0 fat    18773 b- defN 23-May-15 06:21 deep_training/nlp/models/moss/quantization.py
+-rw-rw-rw-  2.0 fat    15939 b- defN 23-Apr-24 00:32 deep_training/nlp/models/moss/tokenization_moss.py
+-rw-rw-rw-  2.0 fat      203 b- defN 23-May-04 00:28 deep_training/nlp/models/prompt/__init__.py
+-rw-rw-rw-  2.0 fat    12062 b- defN 23-May-04 00:28 deep_training/nlp/models/prompt/configuration.py
+-rw-rw-rw-  2.0 fat    52124 b- defN 23-May-15 06:03 deep_training/nlp/models/prompt/prompt_model.py
+-rw-rw-rw-  2.0 fat     3551 b- defN 23-May-04 00:28 deep_training/nlp/models/prompt/save_and_load.py
+-rw-rw-rw-  2.0 fat     1917 b- defN 23-May-04 00:28 deep_training/nlp/models/prompt/utils.py
+-rw-rw-rw-  2.0 fat       54 b- defN 23-May-11 01:00 deep_training/nlp/models/rl/__init__.py
+-rw-rw-rw-  2.0 fat      272 b- defN 23-May-15 00:35 deep_training/nlp/models/rl/modeling.py
+-rw-rw-rw-  2.0 fat    21581 b- defN 23-May-19 04:12 deep_training/nlp/models/rl/modeling_ilql.py
+-rw-rw-rw-  2.0 fat    42065 b- defN 23-May-19 04:12 deep_training/nlp/models/rl/modeling_ppo.py
+-rw-rw-rw-  2.0 fat     8163 b- defN 23-May-19 03:28 deep_training/nlp/models/rl/utils.py
+-rw-rw-rw-  2.0 fat      102 b- defN 22-Nov-22 08:00 deep_training/nlp/models/splinker/__init__.py
+-rw-rw-rw-  2.0 fat     2866 b- defN 23-Apr-25 03:34 deep_training/nlp/models/splinker/splinker.py
+-rw-rw-rw-  2.0 fat    14478 b- defN 23-Feb-11 09:07 deep_training/nlp/models/t5decoder/__init__.py
+-rw-rw-rw-  2.0 fat     6646 b- defN 23-Feb-09 00:28 deep_training/nlp/models/t5encoder/__init__.py
+-rw-rw-rw-  2.0 fat       56 b- defN 22-Dec-14 08:02 deep_training/nlp/optimizer/__init__.py
+-rw-rw-rw-  2.0 fat     5225 b- defN 23-Mar-08 00:14 deep_training/nlp/optimizer/lamb.py
+-rw-rw-rw-  2.0 fat       99 b- defN 23-Mar-02 05:27 deep_training/nlp/optimizer/lion/__init__.py
+-rw-rw-rw-  2.0 fat     2516 b- defN 23-May-10 03:20 deep_training/nlp/optimizer/lion/lion.py
+-rw-rw-rw-  2.0 fat     2499 b- defN 23-May-10 03:18 deep_training/nlp/optimizer/lion/triton.py
+-rw-rw-rw-  2.0 fat       79 b- defN 23-Apr-27 00:33 deep_training/nlp/rl/__init__.py
+-rw-rw-rw-  2.0 fat       88 b- defN 23-May-15 00:35 deep_training/nlp/rl/ilql/__init__.py
+-rw-rw-rw-  2.0 fat     2232 b- defN 23-May-16 05:01 deep_training/nlp/rl/ilql/configuration.py
+-rw-rw-rw-  2.0 fat     3691 b- defN 23-May-15 00:35 deep_training/nlp/rl/ilql/data_define.py
+-rw-rw-rw-  2.0 fat     7800 b- defN 23-May-15 02:51 deep_training/nlp/rl/ilql/ilql_dataset.py
+-rw-rw-rw-  2.0 fat     6244 b- defN 23-May-16 07:17 deep_training/nlp/rl/ilql/ilql_module.py
+-rw-rw-rw-  2.0 fat    35681 b- defN 23-May-17 00:24 deep_training/nlp/rl/ilql/ilql_trainer.py
+-rw-rw-rw-  2.0 fat       55 b- defN 23-Apr-27 00:33 deep_training/nlp/rl/ppo/__init__.py
+-rw-rw-rw-  2.0 fat     3460 b- defN 23-May-15 00:35 deep_training/nlp/rl/ppo/configuration.py
+-rw-rw-rw-  2.0 fat     3201 b- defN 23-May-15 00:35 deep_training/nlp/rl/ppo/data_define.py
+-rw-rw-rw-  2.0 fat     3344 b- defN 23-May-15 00:35 deep_training/nlp/rl/ppo/ppo_dataset.py
+-rw-rw-rw-  2.0 fat    10103 b- defN 23-May-15 09:17 deep_training/nlp/rl/ppo/ppo_module.py
+-rw-rw-rw-  2.0 fat    47376 b- defN 23-May-17 00:24 deep_training/nlp/rl/ppo/ppo_trainer.py
+-rw-rw-rw-  2.0 fat       88 b- defN 23-May-15 00:35 deep_training/nlp/rl/rl_base/__init__.py
+-rw-rw-rw-  2.0 fat     3724 b- defN 23-May-15 00:35 deep_training/nlp/rl/rl_base/rl_dataset.py
+-rw-rw-rw-  2.0 fat    10700 b- defN 23-May-15 00:35 deep_training/nlp/rl/utils/__init__.py
+-rw-rw-rw-  2.0 fat     3529 b- defN 23-May-15 00:35 deep_training/nlp/rl/utils/configuration.py
+-rw-rw-rw-  2.0 fat     9844 b- defN 23-May-15 00:35 deep_training/nlp/rl/utils/logging.py
+-rw-rw-rw-  2.0 fat     2868 b- defN 22-Dec-14 08:00 deep_training/nlp/scheduler/__init__.py
+-rw-rw-rw-  2.0 fat     7056 b- defN 23-May-17 00:24 deep_training/nlp/utils/__init__.py
+-rw-rw-rw-  2.0 fat     6323 b- defN 23-Jan-29 01:07 deep_training/nlp/utils/adversarial.py
+-rw-rw-rw-  2.0 fat    15256 b- defN 23-Jan-03 01:54 deep_training/nlp/utils/nlputils.py
+-rw-rw-rw-  2.0 fat      795 b- defN 23-Jan-11 07:02 deep_training/nlp/utils/spearman.py
+-rw-rw-rw-  2.0 fat       53 b- defN 23-Mar-07 01:25 deep_training/tfnlp/__init__.py
+-rw-rw-rw-  2.0 fat       53 b- defN 23-Mar-07 01:25 deep_training/tfnlp/layers/__init__.py
+-rw-rw-rw-  2.0 fat       53 b- defN 23-Mar-07 01:25 deep_training/tfnlp/losses/__init__.py
+-rw-rw-rw-  2.0 fat       53 b- defN 23-Mar-07 01:25 deep_training/tfnlp/metrics/__init__.py
+-rw-rw-rw-  2.0 fat       53 b- defN 23-Mar-07 01:25 deep_training/tfnlp/models/__init__.py
+-rw-rw-rw-  2.0 fat       53 b- defN 23-Mar-07 01:25 deep_training/tfnlp/optimizer/__init__.py
+-rw-rw-rw-  2.0 fat       53 b- defN 23-Mar-07 01:25 deep_training/tfnlp/scheduler/__init__.py
+-rw-rw-rw-  2.0 fat       53 b- defN 23-Mar-07 01:26 deep_training/tfnlp/utils/__init__.py
+-rw-rw-rw-  2.0 fat       55 b- defN 23-Mar-07 01:20 deep_training/utils/__init__.py
+-rw-rw-rw-  2.0 fat     1941 b- defN 23-Mar-07 01:20 deep_training/utils/distributed.py
+-rw-rw-rw-  2.0 fat     1724 b- defN 23-Mar-07 01:22 deep_training/utils/func.py
+-rw-rw-rw-  2.0 fat     5117 b- defN 23-Feb-21 09:01 deep_training/utils/maskedlm.py
+-rw-rw-rw-  2.0 fat    14500 b- defN 23-May-11 00:39 deep_training/utils/trainer.py
+-rw-rw-rw-  2.0 fat      608 b- defN 23-May-19 04:18 deep_training-0.1.5.post3.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       92 b- defN 23-May-19 04:18 deep_training-0.1.5.post3.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat       14 b- defN 23-May-19 04:18 deep_training-0.1.5.post3.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat    17964 b- defN 23-May-19 04:19 deep_training-0.1.5.post3.dist-info/RECORD
+185 files, 1245180 bytes uncompressed, 316877 bytes compressed:  74.6%
```

## zipnote {}

```diff
@@ -537,20 +537,20 @@
 
 Filename: deep_training/utils/maskedlm.py
 Comment: 
 
 Filename: deep_training/utils/trainer.py
 Comment: 
 
-Filename: deep_training-0.1.5.post2.dist-info/METADATA
+Filename: deep_training-0.1.5.post3.dist-info/METADATA
 Comment: 
 
-Filename: deep_training-0.1.5.post2.dist-info/WHEEL
+Filename: deep_training-0.1.5.post3.dist-info/WHEEL
 Comment: 
 
-Filename: deep_training-0.1.5.post2.dist-info/top_level.txt
+Filename: deep_training-0.1.5.post3.dist-info/top_level.txt
 Comment: 
 
-Filename: deep_training-0.1.5.post2.dist-info/RECORD
+Filename: deep_training-0.1.5.post3.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## deep_training/setup.py

```diff
@@ -1,15 +1,15 @@
 #! -*- coding: utf-8 -*-
 
 from setuptools import setup, find_packages
 
 ignore = ['test','tests']
 setup(
     name='deep_training',
-    version='0.1.5@post2',
+    version='0.1.5@post3',
     description='an easy training architecture',
     long_description='torch_training: https://github.com/ssbuild/deep_training.git',
     license='Apache License 2.0',
     url='https://github.com/ssbuild/deep_training',
     author='ssbuild',
     author_email='9727464@qq.com',
     install_requires=['lightning>=2',
```

## deep_training/nlp/models/rl/modeling_ilql.py

```diff
@@ -39,30 +39,30 @@
     Gather vectors at idxs along dim from x
     """
     idxs = idxs.unsqueeze(-1).expand(idxs.shape[0], idxs.shape[1], x.shape[-1])
     return x.gather(dim=dim, index=idxs)
 
 class ILQLHeads(nn.Module):
     def __init__(
-        self,
-        hidden_size: int,
-        vocab_size: int,
-        two_qs: bool,
-        alpha: float,
-        dtype: type,
-        head_size: int,
-
+            self,
+            hidden_size: int,
+            vocab_size: int,
+            two_qs: bool,
+            alpha: float,
+            dtype: type,
+            head_size: int,
+            up_sampling_score: int = None,
     ):
         super().__init__()
 
         self.hidden_size = hidden_size
         self.vocab_size = vocab_size
         self.two_qs = two_qs
         self.alpha = alpha
-        self.score = make_head(self.hidden_size, head_size, dtype)
+        self.score = make_head(self.hidden_size, head_size, dtype,up_sampling_score=up_sampling_score)
 
         n_qs = 2 if self.two_qs else 1
         self.q_heads = nn.ModuleList(make_head(self.hidden_size, self.vocab_size, dtype) for _ in range(n_qs))
         self.q_heads_target = nn.ModuleList(copy.deepcopy(q_head) for q_head in self.q_heads)
 
         for target_q_head in self.q_heads_target:
             target_q_head.requires_grad_(False)
@@ -125,27 +125,31 @@
     References:
         [1] Snell et al., "Offline RL for Natural Language Generation with Implicit Language Q Learning",
             https://arxiv.org/abs/2206.11871, 2022
     """
 
 
     def __init__(
-        self, *args,
-        two_qs: bool = True,
-        alpha: float = 0.99,
-        **kwargs,
+            self, *args,
+            two_qs: bool = True,
+            alpha: float = 0.99,
+            hidden_size=None, 
+            up_sampling_score=False,
+            **kwargs,
     ):
         super(AutoModelForCausalLMWithILQLHeads,self).__init__(*args, **kwargs)
         config = self.model.config
-        hidden_size = hf_get_hidden_size(config)
+        hidden_size = hidden_size or hf_get_hidden_size(config)
         vocab_size = self.config.vocab_size
         dtype = next(hf_get_lm_head(self.model).parameters()).dtype
         self.two_qs = two_qs
         self.alpha = alpha
-        self.ilql_heads = ILQLHeads(hidden_size, vocab_size, self.two_qs, self.alpha, dtype=dtype,head_size=config.num_labels)
+        self.ilql_heads = ILQLHeads(hidden_size, vocab_size, self.two_qs, self.alpha, dtype=dtype,
+                                    head_size=config.num_labels,
+                                    up_sampling_score=up_sampling_score)
 
     def forward(
         self,
         *args,
         actions_ixs=None,
         states_ixs=None,
         **kwargs
@@ -261,27 +265,31 @@
 
 
 class AutoModelForSeq2SeqLMWithILQLHeads(TransformerForSeq2SeqLM):
     """This is a wrapper around huggingface AutoModelForSeq2Seq with two additional scalar heads"""
 
 
     def __init__(
-        self, *args,
-        two_qs: bool = True,
-        alpha: float = 0.99,
-        **kwargs,
+            self, *args,
+            two_qs: bool = True,
+            alpha: float = 0.99,
+            hidden_size=None,
+            up_sampling_score=False,
+            **kwargs,
     ):
         super().__init__(*args,**kwargs)
         config = self.model.config
-        hidden_size = hf_get_hidden_size(config)
+        hidden_size = hidden_size or hf_get_hidden_size(config)
         vocab_size = config.vocab_size
         dtype = next(hf_get_lm_head(self.model).parameters()).dtype
         self.two_qs = two_qs
         self.alpha = alpha
-        self.ilql_heads = ILQLHeads(hidden_size, vocab_size, self.two_qs, self.alpha, dtype=dtype,head_size=config.num_labels)
+        self.ilql_heads = ILQLHeads(hidden_size, vocab_size, self.two_qs, self.alpha, dtype=dtype,
+                                    head_size=config.num_labels,
+                                    up_sampling_score=up_sampling_score)
 
     def sync_target_q_heads(self):
         self.ilql_heads.sync_target_q_heads()
 
     # def state_dict(self, *args, **kwargs):
     #     """
     #     Returns the state dictionary of the model. We add the state dictionary of the ilql heads
@@ -398,27 +406,31 @@
     References:
         [1] Snell et al., "Offline RL for Natural Language Generation with Implicit Language Q Learning",
             https://arxiv.org/abs/2206.11871, 2022
     """
 
 
     def __init__(
-        self, *args,
-        two_qs: bool = True,
-        alpha: float = 0.99,
-        **kwargs,
+            self, *args,
+            two_qs: bool = True,
+            alpha: float = 0.99,
+            hidden_size=None,
+            up_sampling_score=False,
+            **kwargs,
     ):
         super(ChatglmModelForCausalLMWithILQLHeads,self).__init__(*args, **kwargs)
         config = self.model.config
-        hidden_size = hf_get_hidden_size(config)
+        hidden_size = hidden_size or hf_get_hidden_size(config)
         vocab_size = self.config.vocab_size
         dtype = next(hf_get_lm_head(self.model).parameters()).dtype
         self.two_qs = two_qs
         self.alpha = alpha
-        self.ilql_heads = ILQLHeads(hidden_size, vocab_size, self.two_qs, self.alpha, dtype=dtype,head_size=config.num_labels)
+        self.ilql_heads = ILQLHeads(hidden_size, vocab_size, self.two_qs, self.alpha, dtype=dtype,
+                                    head_size=config.num_labels,
+                                    up_sampling_score=up_sampling_score)
 
     def forward(
         self,
         *args,
         actions_ixs=None,
         states_ixs=None,
         **kwargs
```

## deep_training/nlp/models/rl/modeling_ppo.py

```diff
@@ -4,26 +4,29 @@
 # @FileName: ppo_modeling
 
 from typing import Optional, Tuple, Union
 import torch
 from torch import nn
 from transformers.utils import ModelOutput
 from .utils import CausalLMOutputWithValue, Seq2SeqLMOutputWithValue, hf_get_decoder_blocks, hf_get_decoder_final_norm, \
-    hf_get_lm_head, hf_get_hidden_size, hf_get_num_hidden_layers, CausalPrefixLMOutputWithValue
+    hf_get_lm_head, hf_get_hidden_size, hf_get_num_hidden_layers, CausalPrefixLMOutputWithValue, make_head
 from ..chatglm import ChatGLMForConditionalGeneration, TransformerChatGlmLMHeadModel
 from ..transformer import TransformerForCausalLM,TransformerForSeq2SeqLM
 
 class AutoModelForCausalLMWithValueHead(TransformerForCausalLM):
-    def __init__(self, *args, **kwargs):
+    def __init__(self, *args,hidden_size=None,up_sampling_score=False, **kwargs):
         super(AutoModelForCausalLMWithValueHead, self).__init__(*args, **kwargs)
         # base_model_prefix = self.base_model_prefix[:-1] if self.base_model_prefix.endswith(
         #     '_') else self.base_model_prefix
         # self.transformer_bone = getattr(self.model, base_model_prefix, None)
         # assert self.transformer_bone is not None
-        self.score = nn.Linear(self.config.hidden_size, self.config.num_labels)
+        self.score = make_head( hidden_size or hf_get_hidden_size(self.config), self.config.num_labels,up_sampling_score=up_sampling_score)
+
+
+
 
     def generate(self, *args, **kwargs) -> Union[ModelOutput, torch.LongTensor]:
         return self.model.generate(*args, **kwargs)
 
     def forward(self, *args, **inputs):
         return_dict = inputs.get('return_dict', False)
         if not return_dict:
@@ -37,17 +40,17 @@
         return CausalLMOutputWithValue(**outputs, value=value)
 
 class AutoModelForSeq2SeqLMWithValueHead(TransformerForSeq2SeqLM):
     """An `AutoModel` class wrapper for `transformers` sequence-to-sequence
     models that have a language modeling head and a value head
     """
 
-    def __init__(self, *args, **kwargs):
+    def __init__(self, *args,hidden_size=None,up_sampling_score=False, **kwargs):
         super(AutoModelForSeq2SeqLMWithValueHead, self).__init__(*args, **kwargs)
-        self.score = nn.Linear(self.config.hidden_size, self.config.num_labels)
+        self.score = make_head( hidden_size or hf_get_hidden_size(self.config), self.config.num_labels,up_sampling_score=up_sampling_score)
 
     def forward(self, *args, **inputs) -> Seq2SeqLMOutputWithValue:
         return_dict = inputs.get('return_dict', False)
         if not return_dict:
             inputs.update({"return_dict": True})
         inputs["output_hidden_states"] = True
         outputs = self.model(**inputs)
@@ -58,21 +61,22 @@
             return outputs
         return Seq2SeqLMOutputWithValue(**outputs, value=value)
 
     def generate(self, *args, **kwargs) -> Union[ModelOutput, torch.LongTensor]:
         return self.model.generate(*args, **kwargs)
 
 class AutoModelForCausalPrefixLMWithValueHead(TransformerForCausalLM):
-    def __init__(self, *args, **kwargs):
+    def __init__(self, *args,hidden_size=None,up_sampling_score=False, **kwargs):
         super(AutoModelForCausalPrefixLMWithValueHead, self).__init__(*args, **kwargs)
         # base_model_prefix = self.base_model_prefix[:-1] if self.base_model_prefix.endswith(
         #     '_') else self.base_model_prefix
         # self.transformer_bone = getattr(self.model, base_model_prefix, None)
         # assert self.transformer_bone is not None
-        self.score = nn.Linear(self.config.hidden_size, self.config.num_labels)
+        self.score = make_head(hidden_size or hf_get_hidden_size(self.config), self.config.num_labels,
+                               up_sampling_score=up_sampling_score)
 
     def generate(self, *args, **kwargs) -> Union[ModelOutput, torch.LongTensor]:
         return self.model.generate(*args, **kwargs)
 
     def forward(self, *args, **inputs):
         return_dict = inputs.get('return_dict', False)
         if not return_dict:
@@ -82,21 +86,22 @@
         value = self.score(outputs.hidden_states[-1]).squeeze(-1)
         if not return_dict:
             outputs = (outputs.logits,) + outputs[1:] + (value,)
             return outputs
         return CausalPrefixLMOutputWithValue(**outputs, value=value)
 
 class ChatglmModelForCausalPrefixLMWithValueHead(TransformerChatGlmLMHeadModel):
-    def __init__(self, *args, **kwargs):
+    def __init__(self, *args,hidden_size=None,up_sampling_score=False, **kwargs):
         super(ChatglmModelForCausalPrefixLMWithValueHead, self).__init__(*args, **kwargs)
         # base_model_prefix = self.base_model_prefix[:-1] if self.base_model_prefix.endswith(
         #     '_') else self.base_model_prefix
         # self.transformer_bone = getattr(self.model, base_model_prefix, None)
         # assert self.transformer_bone is not None
-        self.score = nn.Linear(self.config.hidden_size, self.config.num_labels)
+        self.score = make_head(hidden_size or hf_get_hidden_size(self.config), self.config.num_labels,
+                               up_sampling_score=up_sampling_score)
 
     def generate(self, *args, **kwargs) -> Union[ModelOutput, torch.LongTensor]:
         return self.model.generate(*args, **kwargs)
 
     def forward(self, *args, **inputs):
         return_dict = inputs.get('return_dict', False)
         if not return_dict:
@@ -199,15 +204,15 @@
 #
 #         # The branch is defined by the last `num_layers_unfrozen` layers of the pretrained model
 #         decoder_blocks = copy.deepcopy(hf_get_decoder_blocks(base_model))
 #         self.decoder_blocks = nn.ModuleList(list(decoder_blocks)[-num_layers_unfrozen:])
 #         self.final_norm = copy.deepcopy(hf_get_decoder_final_norm(base_model))
 #         self.lm_head = copy.deepcopy(hf_get_lm_head(base_model))
 #
-#         self.hidden_size = hf_get_hidden_size(self.config)
+#         self.hidden_size = hidden_size = kwargs.get('hidden_size',None) or hf_get_hidden_size(self.config)
 #         self.model_parallel = False
 #         self.device_map = None
 #         self.last_device = None
 #         self.gradient_checkpointing = False
 #
 #         # Freeze the entire branch
 #         for parameter in self.parameters():
```

## deep_training/nlp/models/rl/utils.py

```diff
@@ -1,10 +1,11 @@
 # -*- coding: utf-8 -*-
 # @Time    : 2023/5/11 9:07
 import functools
+import typing
 from dataclasses import dataclass
 from typing import Optional, Tuple, Union
 import torch
 from torch import nn
 from transformers import PretrainedConfig
 from transformers.utils import ModelOutput
 
@@ -40,16 +41,18 @@
     encoder_hidden_states: Optional[Tuple[torch.FloatTensor]] = None
     encoder_attentions: Optional[Tuple[torch.FloatTensor]] = None
     value: Optional[torch.FloatTensor] = None
 
 
 
 
-def make_head(n_embd: int, out: int, dtype: type = torch.float32) -> nn.Sequential:
+def make_head(n_embd: int, out: int, dtype: type = None,up_sampling_score=False) -> typing.Union[nn.Sequential,nn.Module]:
     """Returns a generic sequential MLP head."""
+    if not up_sampling_score:
+        return nn.Linear(n_embd, out, dtype=dtype)
     return nn.Sequential(
         nn.Linear(n_embd, n_embd * 2, dtype=dtype),
         nn.ReLU(),
         nn.Linear(n_embd * 2, out, dtype=dtype),
     )
```

## Comparing `deep_training-0.1.5.post2.dist-info/METADATA` & `deep_training-0.1.5.post3.dist-info/METADATA`

 * *Files 18% similar despite different names*

```diff
@@ -1,21 +1,24 @@
 Metadata-Version: 2.1
 Name: deep-training
-Version: 0.1.5-post2
+Version: 0.1.5-post3
 Summary: an easy training architecture
 Home-page: https://github.com/ssbuild/deep_training
 Author: ssbuild
 Author-email: 9727464@qq.com
 License: Apache License 2.0
+Platform: UNKNOWN
 Requires-Dist: lightning (>=2)
 Requires-Dist: numpy-io (<0.1.0,>=0.0.2)
 Requires-Dist: sentencepiece
 Requires-Dist: numpy
 Requires-Dist: transformers (>=4.22)
 Requires-Dist: seqmetric
 Requires-Dist: scipy
 Requires-Dist: scikit-learn
 Requires-Dist: tensorboard
 Requires-Dist: tqdm
 Requires-Dist: six
 
 torch_training: https://github.com/ssbuild/deep_training.git
+
+
```

## Comparing `deep_training-0.1.5.post2.dist-info/RECORD` & `deep_training-0.1.5.post3.dist-info/RECORD`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 deep_training/__init__.py,sha256=bhATnUT4VEzwvA8_8IwxspnDRKf32ZgEeHYCN2E5Dd4,47
-deep_training/setup.py,sha256=KUgjZFrcOs83Q9tnfpCnb3KZht9dVPKHUiNwaupOjWA,903
+deep_training/setup.py,sha256=-v6dGBMVbA2NdIHvjdQT21_p26LoeDKVPheZWql7h1E,903
 deep_training/cv/__init__.py,sha256=J-zlKxMsAfAgoO0vSAzgYJXSuMSJcJ7NKAPKeaeC3TM,55
 deep_training/data_helper/__init__.py,sha256=P8rAMalR6xNepAf-9ldGoOSsEiUtur8Px6gUpTXQhd8,195
 deep_training/data_helper/data_helper.py,sha256=Pe45VeRSRl7izzI5TVfsZ6PnzGK3tyfGWMxGsoclnLs,17724
 deep_training/data_helper/data_module.py,sha256=EmXCTU2jLnldgHubQL4lpwzmlJErSVJf7YIotbQBQJU,5041
 deep_training/data_helper/training_args.py,sha256=XGUXdty0SE6n8xqk6J0lySFvaYSGMVo2zuq6paFQ8sM,12121
 deep_training/nlp/__init__.py,sha256=L4_ltrwpG8mrgN1hZRKimefLHgjhRYyXVtLMFzr1grw,70
 deep_training/nlp/layers/__init__.py,sha256=zbd9GfR02_YVgsTJSXjfyIcQwj8PmG4PscMdA0p6ONI,56
@@ -127,17 +127,17 @@
 deep_training/nlp/models/prompt/__init__.py,sha256=D8B65xX2WyGoV4PBPmc1NujefRcgOz1DUq9zcYbBE2g,203
 deep_training/nlp/models/prompt/configuration.py,sha256=q08sC6BzMcS8yoyV3aMWCXeeZH2fleIB0rn_i98Iw_Y,12062
 deep_training/nlp/models/prompt/prompt_model.py,sha256=OPLAhHCOA2aTVTADIOSxF2ZivAuEeeiSk42EsrlHU6U,52124
 deep_training/nlp/models/prompt/save_and_load.py,sha256=A0RtSZUp_Cn7A-zWIEZKtTAa_quWhVTTi9AtsWB5VlE,3551
 deep_training/nlp/models/prompt/utils.py,sha256=nvNO26eHmgIuY2WrfX3IyyH6jDwEJmQv7ieZqUA-n-0,1917
 deep_training/nlp/models/rl/__init__.py,sha256=pg2jplYDS8gj_w4iUzDgKNFpklxdtOfw4xcTyjA-3xU,54
 deep_training/nlp/models/rl/modeling.py,sha256=3B_v9D-fwpkXH_5v3mBgE0P7MXEXvP-DT7ZlD9qBVis,272
-deep_training/nlp/models/rl/modeling_ilql.py,sha256=UGHULIdaW2RGfTtqGz118-5Gf2QLpmQ_K6FZJrLmNys,20838
-deep_training/nlp/models/rl/modeling_ppo.py,sha256=8QTihTT0opQxQOsQwiAYkrhzk9mLrxFbHfL6l-3d9PQ,41532
-deep_training/nlp/models/rl/utils.py,sha256=roKArfIwPDMfjVEVpl720Pgv3rNBD5IArk6jUsvCh6c,8026
+deep_training/nlp/models/rl/modeling_ilql.py,sha256=xBbwzzeo9ek3_XhUP387gObzdBxxYUVCyu5-WKzGreM,21581
+deep_training/nlp/models/rl/modeling_ppo.py,sha256=uvlUzg_6m_qELTYNXrOiDE3tXb7dEEfKVP1ABL9HLYg,42065
+deep_training/nlp/models/rl/utils.py,sha256=BgocGot9OAvgWug8Dd6DIg2ipnSva1vX9F_WuJpBqRA,8163
 deep_training/nlp/models/splinker/__init__.py,sha256=QtgnpJa78vAq9bzfjN67NmHU3dXU6WH84jeyZoD1sBs,102
 deep_training/nlp/models/splinker/splinker.py,sha256=AhIWyfUtNOLqwZn520J-mv8LJwIoDZpo8yNoc4V5Gss,2866
 deep_training/nlp/models/t5decoder/__init__.py,sha256=R9Op4Ysli9isootQQ2FcjhpbG13fNESlmUROu6cfGH0,14478
 deep_training/nlp/models/t5encoder/__init__.py,sha256=692ChfLf2sZWgzhBM37g1PdpmEmsU1R9RRl_uTHRET0,6646
 deep_training/nlp/optimizer/__init__.py,sha256=c4cmx9ebIdqwXBu3N9QbcNNHb32t2MV6fTK9aC2VBGQ,56
 deep_training/nlp/optimizer/lamb.py,sha256=htvZQHPWHG5GCDgo9xCaZikWwRyaD2PjDioIQvX7qXw,5225
 deep_training/nlp/optimizer/lion/__init__.py,sha256=AvYkLp7sOpRIC3a5ejuniUUKyQmmBA1TPJdt2RA7Nqg,99
@@ -175,11 +175,11 @@
 deep_training/tfnlp/scheduler/__init__.py,sha256=69flKnae4cQQyWUDwuYE0w0iaPonvH0P_WjBd_t-IqU,53
 deep_training/tfnlp/utils/__init__.py,sha256=kAmlOWNSpQCHbtT-mAsKGQzQFoWKp2jQf3neCJ0cCRY,53
 deep_training/utils/__init__.py,sha256=JFm7m_LPsS9Oavyxn9rbWqllCmV_zBho19rISlHNX4c,55
 deep_training/utils/distributed.py,sha256=-dhvJ6YHpRxvtZ1_on50IE33fUFW3zKXBKqqK-L1HGM,1941
 deep_training/utils/func.py,sha256=1p8hiQDCyk_gQGKrF7y6Dt66k3jLXSAt2IQeJuHQEl8,1724
 deep_training/utils/maskedlm.py,sha256=o8EB2BbDdh7wdgqz9Oi6SsVr1uBWxV15qfTk2VPjWsU,5117
 deep_training/utils/trainer.py,sha256=F1usofzi1lBVHeieDJ7WWdfd1d0Q7tftktwdJgczlg8,14500
-deep_training-0.1.5.post2.dist-info/METADATA,sha256=Tq1Hd_FRJxjLTt7NYAjwMNcm0i9VFz7GT3On5NpDRoU,588
-deep_training-0.1.5.post2.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-deep_training-0.1.5.post2.dist-info/top_level.txt,sha256=P4qengiW56PZRm1VvlGcseSUCmAaBCsalCviUABZtO0,14
-deep_training-0.1.5.post2.dist-info/RECORD,,
+deep_training-0.1.5.post3.dist-info/METADATA,sha256=T9TphST1yUzUWgqWPcW02YxTymvOHP-zu2ohqDO0Fpw,608
+deep_training-0.1.5.post3.dist-info/WHEEL,sha256=OqRkF0eY5GHssMorFjlbTIq072vpHpF60fIQA6lS9xA,92
+deep_training-0.1.5.post3.dist-info/top_level.txt,sha256=P4qengiW56PZRm1VvlGcseSUCmAaBCsalCviUABZtO0,14
+deep_training-0.1.5.post3.dist-info/RECORD,,
```

